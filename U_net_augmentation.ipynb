{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ChL1PDfpxd0s",
        "cu3vgZW3FW4g",
        "xXGx04FKFJBI",
        "pNhqELxQEE37",
        "s5BxQcqlFPqf",
        "B9IRxAPKD21Q",
        "ra6jlAlntX0M"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niccolo-Rocchi/Medical_Imaging_project/blob/main/U_net_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentazione semantica su radiografie toraciche\n",
        "\n",
        "### Previsione della maschera binaria dell'area affetta da Pneumotorace \n",
        "\n",
        "Pneuomothorax Imaging Challenge - https://siim.org/page/pneumothorax_challenge"
      ],
      "metadata": {
        "id": "_KJ0NO6_wxMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caricamento Pacchetti"
      ],
      "metadata": {
        "id": "KGjYpHWowyZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pydicom albumentations"
      ],
      "metadata": {
        "id": "L_Suctie9Jug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241ac8dd-3e01-4f6a-a17f-5a38a0d2458a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For reading files\n",
        "from pydicom import dcmread \n",
        "import glob\n",
        "from google.colab import drive\n",
        "# For dealing with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "random.seed(123)\n",
        "import os\n",
        "# For plots\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "# For nets\n",
        "import tensorflow as tf\n",
        "from skimage.transform import resize\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers import Concatenate as concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "# Data augmentation\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from albumentations.core.transforms_interface import DualTransform, to_tuple"
      ],
      "metadata": {
        "id": "uDYvI8wlw4Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collegamento Drive e Lettura file"
      ],
      "metadata": {
        "id": "FcLe73R4xBiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive data\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/pneumotorax_data"
      ],
      "metadata": {
        "id": "75NvFbToVeE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data upload from `Data_Preprocesing` notebook\n",
        "train_set = pd.read_csv(\"train_set.csv\")\n",
        "val_set = pd.read_csv(\"val_set.csv\")"
      ],
      "metadata": {
        "id": "9ATQc5RBVZfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RLE to mask conversion provided by competition organizers with the dataset.\n",
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width*height)\n",
        "\n",
        "    if rle != ' -1':\n",
        "      array = np.asarray([int(x) for x in rle.split()])\n",
        "      starts = array[0::2]\n",
        "      lengths = array[1::2]\n",
        "\n",
        "      current_position = 0\n",
        "      for index, start in enumerate(starts):\n",
        "          current_position += start\n",
        "          mask[current_position:current_position+lengths[index]] = 1\n",
        "          current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height, order='F')"
      ],
      "metadata": {
        "id": "R9z7YCstx0wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation list\n",
        "augment_list = [\n",
        "    A.RandomResizedCrop(1024,1024,scale = (1,1), ratio=(0.8, 1.25),p=1),\n",
        "    A.RandomBrightnessContrast(p=1,brightness_limit=0.4,contrast_limit=0.4), \n",
        "    A.ShiftScaleRotate(p=1,scale_limit=0.3,rotate_limit=30,shift_limit=0.1,border_mode=cv2.BORDER_CONSTANT), \n",
        "    A.GridDistortion(p=1,distort_limit=0.5), \n",
        "    A.ElasticTransform(p=1,border_mode=cv2.BORDER_CONSTANT)\n",
        "]"
      ],
      "metadata": {
        "id": "tP8IFSk7bcnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input for Keras' fit function\n",
        "class DataGenerator:\n",
        "\n",
        "  # Method that yields (image, mask) tuple\n",
        "  def data_generator(self, data):\n",
        "    i = 0\n",
        "    while True:\n",
        "      while i < len(data):\n",
        "        # Extract ID and its encoded pixels\n",
        "        id, rle = data[[\"ImageId\",\" EncodedPixels\"]].iloc[i]\n",
        "        # Convert encoded pixels to mask\n",
        "        mask = rle2mask(rle, 1024, 1024)\n",
        "        # Read the image associate to ImageId\n",
        "        try:\n",
        "          dcm_file = dcmread(f\"/content/gdrive/MyDrive/Med Imaging/train_whole/dicom_files/{id}.dcm\")\n",
        "        except:\n",
        "          continue\n",
        "        dcm_image = dcm_file.pixel_array\n",
        "        # Rescale image\n",
        "        image = dcm_image/255\n",
        "        # Expand dimensions\n",
        "        image = np.expand_dims(image, axis=-1)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        # Resize image and mask\n",
        "        mask = tf.keras.layers.Resizing(256, 256, interpolation=\"nearest\", crop_to_aspect_ratio=False)(mask)\n",
        "        image = tf.keras.layers.Resizing(256, 256, interpolation=\"bilinear\", crop_to_aspect_ratio=False)(image)\n",
        "        yield (image, mask)\n",
        "        i += 1\n",
        "\n",
        "  def data_generator_augment(self, data):\n",
        "    i = 0\n",
        "    while True:\n",
        "      while i < len(data):\n",
        "        # Extract ID and its encoded pixels\n",
        "        id, rle = data[[\"ImageId\",\" EncodedPixels\"]].iloc[int(i)]\n",
        "        # Convert encoded pixels to mask\n",
        "        mask = rle2mask(rle, 1024, 1024)\n",
        "        # Read the image associate to ImageId\n",
        "        try:\n",
        "          dcm_file = dcmread(f\"/content/gdrive/MyDrive/Med Imaging/train_whole/dicom_files/{id}.dcm\")\n",
        "        except:\n",
        "          continue\n",
        "        dcm_image = dcm_file.pixel_array\n",
        "        # Rescale image\n",
        "        image = dcm_image/255\n",
        "        if i != int(i):\n",
        "          # Select randomly an augmentation method\n",
        "          augment_method = list(np.random.choice(a = augment_list, replace = False, size = 1))\n",
        "          transform = A.Compose(augment_method)\n",
        "          if augment_method[0] != augment_list[1]:\n",
        "            # Transform image and mask based on the augmentation method\n",
        "            transformed = transform(image=image,mask=mask)\n",
        "            image = transformed['image']\n",
        "            mask = transformed['mask']\n",
        "          else:\n",
        "            image = transform(image=np.float32(image))['image']\n",
        "        # Expand dimensions\n",
        "        image = np.expand_dims(image, axis=-1)\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        # Resize image and mask\n",
        "        mask = tf.keras.layers.Resizing(256, 256, interpolation=\"nearest\", crop_to_aspect_ratio=False)(mask)\n",
        "        image = tf.keras.layers.Resizing(256, 256, interpolation=\"bilinear\", crop_to_aspect_ratio=False)(image)\n",
        "        yield (image, mask)\n",
        "        i += 0.5\n",
        "\n",
        "  # Create train generator for net input\n",
        "  def train_generator(self, batch_size):\n",
        "    # Create a tensorflow iterator\n",
        "    tf_iterator = tf.data.Dataset.from_generator(lambda: self.data_generator(train_set), output_types=(tf.float64, tf.float64))\n",
        "    # Create batch size\n",
        "    tf_iterator = tf_iterator.batch(batch_size)\n",
        "    # Return generator\n",
        "    return tf_iterator\n",
        "\n",
        "   # Create train generator for net input (augmented images)\n",
        "  def train_generator_augmented(self, batch_size):\n",
        "    # Create a tensorflow iterator\n",
        "    tf_iterator = tf.data.Dataset.from_generator(lambda: self.data_generator_augment(train_set), output_types=(tf.float64, tf.float64))\n",
        "    # Create batch size\n",
        "    tf_iterator = tf_iterator.batch(batch_size)\n",
        "    # Return generator\n",
        "    return tf_iterator\n",
        "\n",
        "  # Create validation generator for net input\n",
        "  def val_generator(self, batch_size):\n",
        "    # Create a tensorflow iterator\n",
        "    tf_iterator = tf.data.Dataset.from_generator(lambda: self.data_generator(val_set), output_types=(tf.float64, tf.float64))\n",
        "    # Create batch size\n",
        "    tf_iterator = tf_iterator.batch(batch_size)\n",
        "    # Return generator\n",
        "    return tf_iterator"
      ],
      "metadata": {
        "id": "i2Torw9AR0Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metrics"
      ],
      "metadata": {
        "id": "ChL1PDfpxd0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intersection-Over-Union (IoU), also known as the Jaccard Index\n",
        "def IoU(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    return intersection / union\n",
        "\n",
        "# True Positive Rate\n",
        "def true_positive_rate(y_true, y_pred):\n",
        "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
        "\n",
        "# Dice coefficient\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
        "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)"
      ],
      "metadata": {
        "id": "6OdZ3HuFx7l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss functions"
      ],
      "metadata": {
        "id": "1O01XXqvARWe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqMreoG0e3UD"
      },
      "outputs": [],
      "source": [
        "# Focal loss\n",
        "def focal_loss(gamma=2., alpha=.25):\n",
        "\tdef focal_loss_fixed(y_true, y_pred):\n",
        "\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1+K.epsilon())) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
        "\treturn focal_loss_fixed\n",
        "\n",
        "# Dice loss\n",
        "def dice_loss(y_true, y_pred, smooth=1):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "# BinaryCrossEntropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Net definition and train"
      ],
      "metadata": {
        "id": "banPi8Wuxfyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "metrics = [dice_coef, true_positive_rate, IoU]\n",
        "\n",
        "# Batch and epochs\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "assert(batch_size <= 32)\n",
        "\n",
        "# Callbacks\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "sJtc0z0JWbbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net\n",
        "def create_model(loss):\n",
        "\n",
        "  # Model description\n",
        "  inputs = Input((256, 256, 1))\n",
        "\n",
        "  c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "  c1 = Dropout(0.1) (c1)\n",
        "  c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "  p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "  c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "  c2 = Dropout(0.1) (c2)\n",
        "  c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "  p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "  c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "  c3 = Dropout(0.2) (c3)\n",
        "  c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "  p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "  c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "  c4 = Dropout(0.2) (c4)\n",
        "  c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "  p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "  c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "  c5 = Dropout(0.3) (c5)\n",
        "  c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "  u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "  u6 = concatenate()([u6, c4])\n",
        "  c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "  c6 = Dropout(0.2) (c6)\n",
        "  c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "  u7 = concatenate()([u7, c3])\n",
        "  c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "  c7 = Dropout(0.2) (c7)\n",
        "  c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "  u8 = concatenate()([u8, c2])\n",
        "  c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "  c8 = Dropout(0.1) (c8)\n",
        "  c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "  u9 = concatenate(axis=3)([u9, c1])\n",
        "  c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "  c9 = Dropout(0.1) (c9)\n",
        "  c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "  outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "  # Model compilation\n",
        "  model.compile(optimizer='adam', loss = loss, metrics = metrics)\n",
        "\n",
        "  # Return model\n",
        "  return model"
      ],
      "metadata": {
        "id": "zuy0TB9gxjax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Net input generator\n",
        "train_generator = DataGenerator().train_generator(batch_size)\n",
        "train_generator_augmented = DataGenerator().train_generator_augmented(batch_size)\n",
        "val_generator = DataGenerator().val_generator(batch_size)"
      ],
      "metadata": {
        "id": "uUyeVf7pcu2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model trained with Dice Loss - No Augmentation"
      ],
      "metadata": {
        "id": "cu3vgZW3FW4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_1 = dice_loss\n",
        "\n",
        "# Create model\n",
        "dice_model = create_model(loss_1)\n",
        "\n",
        "# Fit model\n",
        "model_focal_history = dice_model.fit(x = train_generator, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = (len(val_set)//batch_size),\n",
        "                          callbacks = callback, \n",
        "                          )"
      ],
      "metadata": {
        "id": "mU4Mid05cFuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model trained with Dice Loss - Augmentation"
      ],
      "metadata": {
        "id": "ONMUxf9NEioD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_1 = dice_loss\n",
        "\n",
        "# Create model\n",
        "dice_model_aug = create_model(loss_1)\n",
        "\n",
        "# Fit model\n",
        "model_focal_aug_history = dice_model_aug.fit(x = train_generator_augmented, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)*2//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = (len(val_set)//batch_size),\n",
        "                          callbacks = callback, \n",
        "                          )"
      ],
      "metadata": {
        "id": "rPzCzuBF1ITa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model trained with Binary Cross Entropy Loss - No Augmentation"
      ],
      "metadata": {
        "id": "xXGx04FKFJBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_2 = 'BinaryCrossentropy'\n",
        "\n",
        "# Create model\n",
        "bce_model = create_model(loss_2)\n",
        "\n",
        "# Fit model\n",
        "model_bce_history = bce_model.fit(x = train_generator, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = (len(val_set)//batch_size),\n",
        "                          callbacks = callback, \n",
        "                          )"
      ],
      "metadata": {
        "id": "IxQ0XpzH1fJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model trained with Binary Cross Entropy Loss - Augmentation"
      ],
      "metadata": {
        "id": "pNhqELxQEE37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_2 = 'BinaryCrossentropy'\n",
        "\n",
        "# Create model\n",
        "bce_model_aug = create_model(loss_2)\n",
        "\n",
        "# Fit model\n",
        "model_bce_aug_history = bce_model_aug.fit(x = train_generator_augmented, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)*2//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = (len(val_set)//batch_size),\n",
        "                          callbacks = callback, \n",
        "                          )"
      ],
      "metadata": {
        "id": "j51rrL-41vwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model trained with Focal Loss - No Augmentation"
      ],
      "metadata": {
        "id": "s5BxQcqlFPqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_3 = focal_loss()\n",
        "\n",
        "# Create model\n",
        "focal_model = create_model(loss_3)\n",
        "\n",
        "# Fit model\n",
        "model_focal_history = focal_model.fit(x = train_generator, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = (len(val_set)//batch_size),\n",
        "                          callbacks = callback, \n",
        "                          )"
      ],
      "metadata": {
        "id": "wcSXj_Mf2C5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model trained with Focal Loss - Augmentation"
      ],
      "metadata": {
        "id": "B9IRxAPKD21Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_3 = focal_loss()\n",
        "\n",
        "# Create model\n",
        "focal_model_aug = create_model(loss_3)\n",
        "\n",
        "# Fit model\n",
        "model_focal_aug_history = focal_model_aug.fit(x = train_generator_augmented, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)*2//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = (len(val_set)//batch_size),\n",
        "                          callbacks = callback, \n",
        "                          )"
      ],
      "metadata": {
        "id": "wI5CHcpZ2SLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "model_focal_aug = Model(inputs=[inputs], outputs=[outputs])\n",
        "# Model compilation\n",
        "model_focal_aug.compile(optimizer='adam', loss=focal_loss(), metrics=[dice_coef,true_positive_rate,IoU])"
      ],
      "metadata": {
        "id": "L4l7EjNaD64R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model fit\n",
        "model_history_focal_aug = model_focal_aug.fit(x = train_generator_augmented, \n",
        "                          epochs = epochs, \n",
        "                          steps_per_epoch=(len(train_set)*2//batch_size),\n",
        "                          validation_data = val_generator,\n",
        "                          validation_steps = 10,\n",
        "                          callbacks = callback \n",
        "                          )"
      ],
      "metadata": {
        "id": "IyGyfz-TD-Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mask Prediction Example"
      ],
      "metadata": {
        "id": "ra6jlAlntX0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_1 = dice_loss\n",
        "\n",
        "# Create model\n",
        "dice_model = create_model(loss_1)\n",
        "\n",
        "# Restore the weights\n",
        "dice_model.load_weights('/content/gdrive/MyDrive/Med Imaging/trained_models/dice_loss_model/dice_loss')\n",
        "\n",
        "history_dice = pd.read_csv('/content/gdrive/MyDrive/Med Imaging/trained_models_history/dice_loss')\n",
        "history_dice"
      ],
      "metadata": {
        "id": "A1sI6AabWICM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_2 = 'BinaryCrossentropy'\n",
        "\n",
        "# Create model\n",
        "bce_model = create_model(loss_2)\n",
        "\n",
        "# Restore the weights\n",
        "bce_model.load_weights('/content/gdrive/MyDrive/Med Imaging/trained_models/bce_model/bce_loss')\n",
        "\n",
        "history_bce = pd.read_csv('/content/gdrive/MyDrive/Med Imaging/trained_models_history/bce_loss')\n",
        "history_bce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ8-59FPWrS6",
        "outputId": "eddba9e0-a1e9-4f1b-9631-75589a299867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f7b0016d030>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss\n",
        "loss_3 = focal_loss()\n",
        "\n",
        "# Create model\n",
        "focal_model = create_model(loss_3)\n",
        "\n",
        "# Restore the weights\n",
        "focal_model.load_weights('/content/gdrive/MyDrive/Med Imaging/trained_models/focal_model/focal_loss')\n",
        "\n",
        "history_focal = pd.read_csv('/content/gdrive/MyDrive/Med Imaging/trained_models_history/focal_loss')\n",
        "history_focal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-wlKwuTUyNj",
        "outputId": "c780bd5c-e863-4824-f57b-305df4dbdb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f8c59ab6b60>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,idx in enumerate(encoded_pixels[:32]['ImageId']): \n",
        "  dcmHead_4 = dcmread(f'/content/gdrive/MyDrive/Med Imaging/train_whole/dicom_files/{idx}.dcm') #confronto con immagine ridotta\n",
        "  img_pred = dcmHead_4.pixel_array/255\n",
        "  img_pred = np.expand_dims(img_pred, axis=-1)\n",
        "  img_pred = tf.keras.layers.Resizing(256, 256, interpolation=\"bilinear\", crop_to_aspect_ratio=False)(img_pred)\n",
        "  test_set[k] = img_pred\n",
        "\n",
        "test_preds = focal_model.predict(test_set)\n",
        "preds_test_thresh = (test_preds <= 0.01).astype(np.uint8)"
      ],
      "metadata": {
        "id": "WMuZMqXkfz7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}