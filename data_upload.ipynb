{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbxLckSgyZ3tQ3dSZrpgJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niccolo-Rocchi/Medical_Imaging_project/blob/main/data_upload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "UAzOXcdIz2JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!pip install pydicom"
      ],
      "metadata": {
        "id": "Y9Wl_73Mz8XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVqMeQ_GxbHh"
      },
      "outputs": [],
      "source": [
        "# For reading files\n",
        "from pydicom import dcmread \n",
        "import glob\n",
        "from google.colab import drive\n",
        "# For dealing with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "random.seed(123)\n",
        "# For plots\n",
        "import matplotlib.pyplot as plt\n",
        "# For nets utils\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive data\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/MyDrive/pneumotorax_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg9w3Cm-01pp",
        "outputId": "d6f8a7be-fc18-4c54-963e-893572b0e674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/DS Lab in Medicine - projects/Medical Imaging - project/pneumotorax_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data upload"
      ],
      "metadata": {
        "id": "7xEjXYjqN7lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read patients IDs and their encoded pixels\n",
        "encoded_pixels = pd.read_csv('./encoded_pixels.csv')\n",
        "# Read dicom files IDs\n",
        "dicom_files_IDs = glob.glob('./dicom_files/*')\n",
        "dicom_files_IDs = pd.DataFrame({\"dicom_ID\" : [re.findall(r\"\\./dicom_files/(.+)\\.dcm\", id)[0] for id in dicom_files_IDs]})\n",
        "# Intersect patients IDs with dicom IDs\n",
        "encoded_pixels = pd.merge(encoded_pixels, dicom_files_IDs, how = \"inner\", left_on = \"ImageId\", right_on = \"dicom_ID\")\n",
        "# Mark healthy patients as \"0\"\n",
        "encoded_pixels[\" EncodedPixels\"] = encoded_pixels[\" EncodedPixels\"].apply(lambda x: x.split())\n",
        "encoded_pixels[\"Health\"] = encoded_pixels[\" EncodedPixels\"].apply(lambda x: 0 if len(x)==1 else 1)"
      ],
      "metadata": {
        "id": "30s0N7ObVVOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find by how many pts healthy vs unhealthy the dataset differ\n",
        "diff = len(encoded_pixels[encoded_pixels[\"Health\"] == 0]) - len(encoded_pixels[encoded_pixels[\"Health\"] == 1])\n",
        "# Select this number of pts in a random manner and drop them in the dataset\n",
        "healthy_idx = list(encoded_pixels[encoded_pixels[\"Health\"] == 0].index)\n",
        "random.shuffle(healthy_idx)\n",
        "encoded_pixels.drop(index = healthy_idx[:diff], inplace = True)\n",
        "# Assert\n",
        "assert(len(encoded_pixels[encoded_pixels[\"Health\"] == 0]) == len(encoded_pixels[encoded_pixels[\"Health\"] == 1]))"
      ],
      "metadata": {
        "id": "mZfFUHgATHAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset indices\n",
        "encoded_pixels.reset_index(drop = True, inplace = True)\n",
        "# Sample the dataset\n",
        "train_frac = 0.7\n",
        "train_set = encoded_pixels.sample(frac = train_frac, random_state = 123)\n",
        "val_set = encoded_pixels.drop(index = train_set.index).sample(frac = 1, random_state = 1)\n",
        "# Assert\n",
        "assert([i for i in val_set.index if i in train_set.index] == [])"
      ],
      "metadata": {
        "id": "U7i2-Xn2eEpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RLE to mask conversion provided by competition organizers with the dataset.\n",
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width* height)\n",
        "    array = np.asarray([int(x) for x in rle])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        current_position += start\n",
        "        mask[current_position:current_position+lengths[index]] = 255\n",
        "        current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height, order='F')"
      ],
      "metadata": {
        "id": "4L1i9ZtCEyRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input for Keras' fit_generator function\n",
        "class DataGenerator:\n",
        "\n",
        "  # Method that yields (image, mask) tuple\n",
        "  def data_generator(self, data):\n",
        "    i = 0\n",
        "    while i < len(data):\n",
        "      # Extract ID and its encoded pixels\n",
        "      id, rle = data[[\"ImageId\",\"EncodedPixels\"]].iloc(i)\n",
        "      # Convert encoded pixels to mask\n",
        "      mask = rle2mask(rle, 1024, 1024)\n",
        "      # Read the image associate to ImageId\n",
        "      try:\n",
        "        dcm_file = dcmread(f\"./dicom_files/{id}.dcm\")\n",
        "      except:\n",
        "        continue\n",
        "      dcm_image = dcm_file.pixel_array\n",
        "      # Rescale image\n",
        "      image = tf.keras.layers.Rescaling(dcm_image, 255)\n",
        "      # Resize image and mask\n",
        "      mask = tf.keras.layers.Resizing(256, 256, interpolation=\"bilinear\", crop_to_aspect_ratio=False)(mask)\n",
        "      image = tf.keras.layers.Resizing(256, 256, interpolation=\"bilinear\", crop_to_aspect_ratio=False)(image)\n",
        "      # Expand image dimension\n",
        "      image = np.expand_dims(image, axis=-1)\n",
        "      yield (image, mask)\n",
        "      i += 1\n",
        "\n",
        "  # Method used to train the net, i.e. to generate training set\n",
        "  def train_generator(self, total_items, batch_size, epochs):\n",
        "    # Create a tensorflow iterator\n",
        "    tf_iterator = tf.data.Dataset.from_generator(self.data_generator(train_set), output_types=(tf.float64, tf.int64))\n",
        "    # Create epochs\n",
        "    tf_iterator = tf_iterator.repeat(epochs)\n",
        "    # Create batches\n",
        "    tf_iterator = tf_iterator.batch(batch_size)\n",
        "    # Convert to a proper iterator\n",
        "    tf_iterator = tf_iterator.make_one_shot_iterator()\n",
        "    # Yield the result\n",
        "    while True:\n",
        "      batch_images, batch_masks = tf_iterator.get_next()\n",
        "      yield (batch_images, batch_masks)\n",
        "\n",
        "  # Method used to generate validation set\n",
        "  def val_generator(self, total_items, batch_size, epochs):\n",
        "    # Create a tensorflow iterator\n",
        "    tf_iterator = tf.data.Dataset.from_generator(self.data_generator(val_set), output_types=(tf.float64, tf.int64))\n",
        "    # Create epochs\n",
        "    tf_iterator = tf_iterator.repeat(epochs)\n",
        "    # Create batches\n",
        "    tf_iterator = tf_iterator.batch(batch_size)\n",
        "    # Convert to a proper iterator\n",
        "    tf_iterator = tf_iterator.make_one_shot_iterator()\n",
        "    # Yield the result\n",
        "    while True:\n",
        "      batch_images, batch_masks = tf_iterator.get_next()\n",
        "      yield (batch_images, batch_masks)"
      ],
      "metadata": {
        "id": "qBhUUfwm18_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. https://towardsdatascience.com/medical-image-dataloaders-in-tensorflow-2-x-ee5327a4398f\n",
        "2. https://stackoverflow.com/questions/55375416/tensorflow-model-fit-using-a-dataset-generator\n",
        "3. https://faroit.com/keras-docs/1.2.0/models/model/\n",
        "4. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling\n",
        "5. https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#from_generator"
      ],
      "metadata": {
        "id": "X2qpVhbBN-HC"
      }
    }
  ]
}